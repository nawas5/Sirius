{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a54e6e74",
   "metadata": {},
   "source": [
    "### Установка chromedriver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1006b6",
   "metadata": {},
   "source": [
    "1. Скачать и установить google chrome браузер\n",
    "2. Посмотреть версию браузера (настройки с троеточием справа -> Help -> About Google Chrome)\n",
    "3. Скачать и установить google-chrome-driver версии, соответствующей версии браузера https://chromedriver.chromium.org/\n",
    "4. Распаковать архив и положить в <путь к проекту>/bin/chromedriver\n",
    "на виндоуз переименовать чтобы не было .exe в расширении, либо в переменной ниже поменять путь к драйверу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7cfb92a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -q selenium "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edf9f4c",
   "metadata": {},
   "source": [
    "### Конфиги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59ac18c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAME_URL = \"chrome://dino/\"\n",
    "CHROMEDRIVER_PATH = \"./bin/chromedriver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb784822",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class Action(Enum):\n",
    "    DO_NOTHING = 0\n",
    "    JUMP = 1\n",
    "    # TODO: Add action DUSK\n",
    "    #DUSK = 2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac768aed",
   "metadata": {},
   "source": [
    "### Среда"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "690fd1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import typing\n",
    "\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageGrab\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fcf3d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ОБЯЗАТЕЛЬНО TODO: Подобрать рамку под себя\n",
    "# Создать environment (см. код ниже)\n",
    "# Начать игру\n",
    "# Подобрать различные варианты через ImageGrab.grab(bbox=(0, 210, 550, 350))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1f48fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCREEN_BBOX = (0, 200, 650, 400)\n",
    "SCREEN_BBOX = (100, 150, 350, 450)\n",
    "#SCREEN_BBOX = (90, 300, 400, 345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65b5042c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAEsCAIAAABlnjnsAAAGsElEQVR4nO3dXVLafBjG4fSdrkDW0CO7GpvIGhWnqymeuAbZgu/Bv5PJBIyI+aL3dR10LDIQ9efjQ2CGb29vbxVk+G/pA4D5yJ0gcieI3Akid4LInSByJ4jcCSJ3gsidIHIniNwJIneCyJ0gcieI3Akid4LInSByJ4jcCSJ3gsidIHIniNwJIneCyJ0gcieI3Akid4LInSByJ4jcCSJ3gsidIHIniNwJIneCyJ0gcieI3Akid4LInSByJ4jcCSJ3gsidIHIniNwJIneCyJ0gcieI3Akid4LInSByJ4jcCSJ3gsidIHIniNwJIneCyJ0gcieI3Akid4LInSByJ4jcCSJ3gsidIHIniNwJIneCyJ0gcifI96UPYC0eHh7e+9TPnz+rqrq9vR39Xsa65d7Nbrfb7n/3+31VVX/+/Gnv9OJ7HPgu9XzlXi7T+zKPbbdbuf+12+2GrzDKD+/kvXz9lns328u9FNC9zsX3+OF3qWvm3I+/zJ7tdmuZIUj6dH94eGjnQdM0vbk46b3UdV0u3O12T09PI95dXddN01RVtd1u67oe8Za7xj3mL+p+mccHVr7/dV3n5l7W0Ofn5/LfpmnKJj3bvTRNUy7f7/flaiPuu+WWz1+1Q1hmCJI73Ycf3s1wL9vttkzf/X7fXm2s6V5OU5R/aeXmPqC377Z78EKHs1LvPSpY1U7fY5khiOl+QvdB5Li33Hvs2D6EHVf3+Kf7Wsofvesi9xO6W/W4t/ypp2ku1j3+6b6Wa9zucnMvK2Z7Rrycq576R9jba0uIU/wOlC/kGouclN2dILnTvWif9Nntds/Pz+1uPdFW/S8Zfg5r5peIHT9n11U+1TRNeu63t7flp7Lb7fb7vRPV55vnRXVnOvkkxvF1LDME+fb29rb0McBMTHeCyJ0gcieI3Akid4LInSByJ4jcCSJ3gsidIHIniNwJIneCrOX17i8vL71Lfvz4sciR8A9b4AXAx2UXbd/dK4ieEVlmCDLrdG/H9pkz++Xl5ebmpqqqzWYz4WERY6bd/bL95Obm5nA4VHJnJJYZgsx3ZuaCB52bzaZM99fX1+6FYx4WSdZyIvJMpf5jfgc4x1S5v3e28VNeX1/Peah6OBzkzjns7gSZZLp/9oTjgN7YPjnFD4eD5Z5zXJj7h7vKKM+GnhluWXgKiw0DLDME+fSzqiMuKlNon4itbDUcuXC6r7P1qrPYvHfKkmQf7+7to8DNZtN9RNi7wkpGafcwVnVgrIHdnSBD071Mx8Ph0D310f34+Mqr4uVl9Aw9VO2uMR/e0ApzL+Q+p8fHx8fHxwUP4P7+/v7+/r3PWmYI4t07GM3io70YGPBX9opI1qlUvobWq85hHEdvmSGI3Akid4LY3VnY3d1d+eD3799T35fpThDTneXNNuDlzlrMEL1lhiCmO/O5u7trR/h7VygfdAd8ubD7qYvHv9yZQy/Zc678XtPDnx0mdyb34VDv+XB+X7zl290JYrozqzKPe6t5b1r3ZnZ74ac2opPkzlp85THomSwzBDHdWd7JHWYKcmdhM1TesswQRO4EkTtB5E4QuRNE7gRxIpJZff2FAF9huhPEdGdy7RNJYw31i19dI3fmMGLxX3klmWWGIKY785nhJb7DTHeCyJ0gcieI3Akid4LInSByJ4jz7oygfdOvNbwb2cA775nujGb4LXzXcAxyJ4i3ESaI6U4QuRNE7gSRO0HkThC5E0TuBJE7QeROELkTRO4EkTtB5E4QuRNE7gSRO0HkThC5E0TuBJE7QeROELkTRO4EkTtB5E4QuRNE7gSRO0HkThC5E0TuBJE7QeROELkT5NuvX7+WPgaYielOEG9FRhDTnSByJ8jfN4mv67p76dPT0xIHw0r9M3lMu7vXdX2935rFtZFdy/dw3B/3FL9jQ7mX+7uW7/Ui/D5fF7s7QdZ+IvL4L8wof+K7fyiN5xxrz53L+H0+yTJDENOdIKY7QeROELkTRO4EkTtB5E4QuRNE7gSRO0HkThC5E0TuBJE7QeROELkTRO4EkTtB5E4QuRNE7gSRO0HkThC5E0TuBJE7QeROELkTRO4EkTtB5E4QuRNE7gSRO0HkThC5E0TuBJE7QeROELkTRO4EkTtB5E4QuRNE7gSRO0HkThC5E0TuBJE7QeROELkTRO4EkTtB5E4QuRNE7gSRO0HkThC5E0TuBJE7QeROELkTRO4EkTtB5E4QuRNE7gSRO0HkThC5E0TuBJE7QeROELkTRO4EkTtB5E4QuRNE7gSRO0HkThC5E0TuBJE7Qf4Ht78Gyrd1o7MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=250x300 at 0x1C5E44F2640>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Запускать для подбора бокса ПОСЛЕ создания энвайронмента ниже\n",
    "ImageGrab.grab(bbox=SCREEN_BBOX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2ee8bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5944de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63bbed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    def __init__(\n",
    "        self, \n",
    "        chrome_driver_path: str, \n",
    "        game_url: str, \n",
    "        speed: typing.Optional[int] = None,\n",
    "        acceleration: typing.Optional[float] = None,\n",
    "    ) -> None:\n",
    "        self.driver = webdriver.Chrome(executable_path=chrome_driver_path)\n",
    "        # Обязательно TODO: убедиться что эти параметры годятся \n",
    "        self.driver.set_window_position(x=-20, y=-20)\n",
    "        self.driver.set_window_size(550, 450)\n",
    "        try:\n",
    "            self.driver.get('chrome://dino')\n",
    "        except Exception:\n",
    "            pass   # ignore\n",
    "        \n",
    "        if speed:\n",
    "            self.driver.execute_script(f\"Runner.instance_.setSpeed({speed})\")\n",
    "        \n",
    "        if acceleration:\n",
    "            self.driver.execute_script(f\"Runner.config.ACCELERATION={acceleration}\")\n",
    "\n",
    "    def start_game(self):\n",
    "        self.driver.find_element(By.TAG_NAME, \"body\").send_keys(Keys.SPACE)\n",
    "        time.sleep(2)\n",
    "        \n",
    "    def close_game(self):\n",
    "        self.driver.close()\n",
    "            \n",
    "    def perform_action(self, action: Action) -> (typing.Optional[np.ndarray], float):\n",
    "        state = self.get_screen()\n",
    "        if action == Action.DO_NOTHING:\n",
    "            pass\n",
    "        elif action == Action.JUMP:\n",
    "            # TODO: Принять решение не нужна ли тут какая-то пауза убедиться что прыжок закончили\n",
    "            self.driver.find_element(By.TAG_NAME, \"body\").send_keys(Keys.SPACE)\n",
    "            time.sleep(0.5)\n",
    "        elif action == Action.DUSK:\n",
    "            # TODO: (ТОЛЬКО ЕСЛИ ДОБАВИЛИ СООТВЕТСТВУЮШИЙ ЭКШН В АГЕНТА) \n",
    "            # Если был выбран нырок, то возможно стоит подольше его подержать, а не просто один раз кликнуть\n",
    "            self.driver.driver.find_element(By.TAG_NAME, \"body\").send_keys(Keys.ARRAYS_DOWN)\n",
    "        else:\n",
    "            raise Exception(f\"Unsupported action {action}\")\n",
    "        \n",
    "        if self.has_crashed():\n",
    "            return None, 0\n",
    "        else:\n",
    "            # TODO: Попробовать разные варианты вычисления награды. Может штрафовать за лишние прыжки, например\n",
    "            reward = self.get_score() ** 1.6\n",
    "        return state, reward\n",
    "            \n",
    "    def has_crashed(self) -> bool:\n",
    "        return self.driver.execute_script(\"return Runner.instance_.crashed\")\n",
    "    \n",
    "    def restart(self) -> None:\n",
    "        self.driver.execute_script(\"Runner.instance_.restart()\")\n",
    "\n",
    "    def get_screen(self) -> np.ndarray:\n",
    "        screen = ImageGrab.grab(bbox=SCREEN_BBOX)\n",
    "        screen = np.array(screen)\n",
    "        return self.preprocess_screen(screen)\n",
    "        \n",
    "    def preprocess_screen(self, screen: np.ndarray) -> np.ndarray:\n",
    "        # TODO: Добавить больше препроцессинга. Возможные идеи:\n",
    "        #    Убрать облака?\n",
    "        #    Убрать линию \"дороги\"?\n",
    "        #    Обрезать изображение?\n",
    "        #    Сделать черно-белым?\n",
    "        #    Поменять размер?\n",
    "        #    Сделать динозавра прямоугольником? :) \n",
    "        #    Меньше будущей информации?\n",
    "        #    Ваши идеи\n",
    "        return cv2.cvtColor(screen, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    def get_score(self) -> int:\n",
    "        score_array = self.driver.execute_script(\"return Runner.instance_.distanceMeter.digits\")\n",
    "        score = ''.join(score_array)\n",
    "        return int(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8c779cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-35-14ff86949804>:9: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self.driver = webdriver.Chrome(executable_path=chrome_driver_path)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Подобрать какая скорость больше подойдет\n",
    "# TODO: Принять решение будете ли использовать ускорение или лучше задать его в ноль (тогда не будет птичек еще)\n",
    "\n",
    "environment = Environment(CHROMEDRIVER_PATH, GAME_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "127f00cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.start_game()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "baf25c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255]], dtype=uint8),\n",
       " 101.96145121984944)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment.perform_action(Action.JUMP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "151c9795",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        ...,\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255]], dtype=uint8),\n",
       " 111.17464760577515)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment.perform_action(Action.DO_NOTHING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2636a8cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3191b0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8083383",
   "metadata": {},
   "source": [
    "### DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ac319c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, screen_width, screen_height, action_count):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=5, stride=2)\n",
    "        #conv1_out_width = self.conv2d_size_out(screen_width)\n",
    "        #conv1_out_height = self.conv2d_size_out(screen_height)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "\n",
    "        \n",
    "        #self.flatten = nn.Flatten()\n",
    "        #self.head = nn.Linear(conv1_out_width * conv1_out_height * 16, action_count)\n",
    "        \n",
    "        def conv2d_size_out(size, kernel_size=5, stride=2) -> int:\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        \n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(screen_width)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(screen_height)))\n",
    "        \n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, action_count)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO: Добавить различные сверточные слои / функции активации / и т.д.\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "\n",
    "        return self.head(x.view(x.size(0), -1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6177fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b668e50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "907b2b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 310)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "screen_height = SCREEN_BBOX[3] - SCREEN_BBOX[1]\n",
    "screen_width = SCREEN_BBOX[2] - SCREEN_BBOX[0]\n",
    "\n",
    "screen_height, screen_width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8448307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_net = DQN(screen_height, screen_width, len(Action)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2e5af0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 45, 310])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = torch.from_numpy(environment.get_screen()).float()\n",
    "batch_state = state.unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "batch_state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe452b44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0701, 0.3497]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_net(batch_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f465cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3793f721",
   "metadata": {},
   "source": [
    "### Агент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd71a681",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import collections as col\n",
    "\n",
    "Transition = col.namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = col.deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "class Agent:\n",
    "    \n",
    "    # TODO: ВАЖНО: Подобрать параметры ниже    \n",
    "\n",
    "    EXPLORATION_STEPS_COUNT = 40   # Количество шагов, когда совершаем ТОЛЬКО exploration \n",
    "    EPS_INITIAL = 0.9   # Начальное значение EPS, после которого начинаем подключать exploitation\n",
    "    EPS_FINAL = 0.05   # Минимальное значение EPS, до которого дойдем\n",
    "    EPS_DECAY_DELTA = 0.05   # Величина, на которую будем уменьшать EPS\n",
    "    EPS_DECAY_STEPS_COUNT = 15  # Через сколько шагов будем снижать EPS\n",
    "    \n",
    "    \n",
    "    \n",
    "    def __init__(self) -> None:\n",
    "        self.eps = 1    # По началу только exploration\n",
    "        self.made_steps_count = 0\n",
    "        self.n_actions = len(Action)\n",
    "        self.policy_net = DQN(screen_height, screen_width, self.n_actions).to(device)\n",
    "        self.optimizer = torch.optim.RMSprop(policy_net.parameters())\n",
    "        self.memory = ReplayMemory(10000)\n",
    "    \n",
    "    def select_action(self, state: np.ndarray) -> Action:\n",
    "        self.made_steps_count += 1\n",
    "        \n",
    "        # Пока еще только exploration\n",
    "        if self.made_steps_count < self.EXPLORATION_STEPS_COUNT:\n",
    "            self.eps = 1\n",
    "        # Начинаем подключать exploitation\n",
    "        elif self.made_steps_count == self.EXPLORATION_STEPS_COUNT:\n",
    "            self.eps = self.EPS_INITIAL\n",
    "        # Каждые EPS_DECAY_STEPS_COUNT шагов на константу уменьшаем eps если он получится не меньше чем EPS_FINAL\n",
    "        elif self.made_steps_count % self.EPS_DECAY_STEPS_COUNT == 0 \\\n",
    "                and self.eps - self.EPS_DECAY_DELTA >= self.EPS_FINAL:\n",
    "            self.eps -= self.EPS_DECAY_DELTA                        \n",
    "        \n",
    "        exploit_prob = random.random()\n",
    "        if exploit_prob > self.eps:\n",
    "            with torch.no_grad():\n",
    "                # Сеть ожидает что у нас обязательно будет размерность для батча. Создаем фиктивную размерность \n",
    "                # Также создаем фиктивную размерность для числа каналов\n",
    "                state_batch = torch.from_numpy(state).float().unsqueeze(0).unsqueeze(0)\n",
    "                batch_action_rewards = policy_net(state_batch)\n",
    "                batch_argmax_actions = batch_action_rewards.max(1).indices\n",
    "                # Взяли нулевой элемент, т.к. у нас батч всего из одного элемента\n",
    "                action_ind = batch_argmax_actions.tolist()[0]\n",
    "        else:\n",
    "            action_ind = random.randrange(self.n_actions)        \n",
    "        return Action(action_ind)    \n",
    "    \n",
    "    def update_reward(self, state: np.ndarray, action: Action, next_state: np.ndarray, reward: int) -> None:\n",
    "        state_batch = torch.from_numpy(state).float().unsqueeze(0).unsqueeze(0)\n",
    "        next_state_batch = torch.from_numpy(next_state).float().unsqueeze(0).unsqueeze(0)\n",
    "        # Индексы действий что мы проделали. Используется чтобы достать текушие оценки Q для проделанных действий\n",
    "        action_batch = torch.from_numpy(np.array([action.value])).unsqueeze(0)\n",
    "        #reward_batch = torch.from_numpy(state).float().unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "        # Получаем текущее \"жадное\" действие для уравнения Беллмана\n",
    "        with torch.no_grad():\n",
    "            next_state_values = policy_net(next_state_batch).max(1)[0]\n",
    "            expected_state_action_values = (next_state_values * 0.99) + reward\n",
    "\n",
    "        # Получаем текущее значение Q для проделанного действия    \n",
    "        state_action_values = policy_net(state_batch).gather(1, action_batch.type(torch.int64))\n",
    "\n",
    "        criterion = nn.SmoothL1Loss()\n",
    "        loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72b0a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2ef3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f6da413",
   "metadata": {},
   "source": [
    "### Цикл обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce00d694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running episode 0\n",
      "Running episode 1\n",
      "Running episode 2\n",
      "Running episode 3\n",
      "Running episode 4\n",
      "Running episode 5\n",
      "Running episode 6\n",
      "Running episode 7\n",
      "Running episode 8\n",
      "Running episode 9\n",
      "Running episode 10\n",
      "Running episode 11\n",
      "Running episode 12\n",
      "Running episode 13\n",
      "Running episode 14\n",
      "Running episode 15\n",
      "Running episode 16\n",
      "Running episode 17\n",
      "Running episode 18\n",
      "Running episode 19\n",
      "Running episode 20\n",
      "Running episode 21\n",
      "Running episode 22\n",
      "Running episode 23\n",
      "Running episode 24\n",
      "Running episode 25\n",
      "Running episode 26\n",
      "Running episode 27\n",
      "Running episode 28\n",
      "Running episode 29\n",
      "Running episode 30\n",
      "Running episode 31\n",
      "Running episode 32\n",
      "Running episode 33\n",
      "Running episode 34\n",
      "Running episode 35\n",
      "Running episode 36\n",
      "Running episode 37\n",
      "Running episode 38\n",
      "Running episode 39\n",
      "Running episode 40\n",
      "Running episode 41\n",
      "Running episode 42\n",
      "Running episode 43\n",
      "Running episode 44\n",
      "Running episode 45\n",
      "Running episode 46\n",
      "Running episode 47\n",
      "Running episode 48\n",
      "Running episode 49\n",
      "Running episode 50\n",
      "Running episode 51\n",
      "Running episode 52\n",
      "Running episode 53\n",
      "Running episode 54\n",
      "Running episode 55\n",
      "Running episode 56\n",
      "Running episode 57\n",
      "Running episode 58\n",
      "Running episode 59\n",
      "Running episode 60\n",
      "Running episode 61\n",
      "Running episode 62\n",
      "Running episode 63\n",
      "Running episode 64\n",
      "Running episode 65\n",
      "Running episode 66\n",
      "Running episode 67\n",
      "Running episode 68\n",
      "Running episode 69\n",
      "Running episode 70\n",
      "Running episode 71\n",
      "Running episode 72\n",
      "Running episode 73\n",
      "Running episode 74\n",
      "Running episode 75\n",
      "Running episode 76\n",
      "Running episode 77\n",
      "Running episode 78\n",
      "Running episode 79\n",
      "Running episode 80\n",
      "Running episode 81\n",
      "Running episode 82\n",
      "Running episode 83\n",
      "Running episode 84\n",
      "Running episode 85\n",
      "Running episode 86\n",
      "Running episode 87\n",
      "Running episode 88\n",
      "Running episode 89\n",
      "Running episode 90\n",
      "Running episode 91\n",
      "Running episode 92\n",
      "Running episode 93\n",
      "Running episode 94\n",
      "Running episode 95\n",
      "Running episode 96\n",
      "Running episode 97\n",
      "Running episode 98\n",
      "Running episode 99\n",
      "Running episode 100\n",
      "Running episode 101\n",
      "Running episode 102\n",
      "Running episode 103\n",
      "Running episode 104\n",
      "Running episode 105\n",
      "Running episode 106\n",
      "Running episode 107\n",
      "Running episode 108\n",
      "Running episode 109\n",
      "Running episode 110\n",
      "Running episode 111\n",
      "Running episode 112\n",
      "Running episode 113\n",
      "Running episode 114\n",
      "Running episode 115\n",
      "Running episode 116\n",
      "Running episode 117\n",
      "Running episode 118\n",
      "Running episode 119\n",
      "Running episode 120\n",
      "Running episode 121\n",
      "Running episode 122\n",
      "Running episode 123\n",
      "Running episode 124\n",
      "Running episode 125\n",
      "Running episode 126\n",
      "Running episode 127\n",
      "Running episode 128\n",
      "Running episode 129\n",
      "Running episode 130\n",
      "Running episode 131\n",
      "Running episode 132\n",
      "Running episode 133\n",
      "Running episode 134\n",
      "Running episode 135\n",
      "Running episode 136\n",
      "Running episode 137\n",
      "Running episode 138\n",
      "Running episode 139\n",
      "Running episode 140\n",
      "Running episode 141\n",
      "Running episode 142\n",
      "Running episode 143\n",
      "Running episode 144\n",
      "Running episode 145\n",
      "Running episode 146\n",
      "Running episode 147\n",
      "Running episode 148\n",
      "Running episode 149\n",
      "Running episode 150\n",
      "Running episode 151\n",
      "Running episode 152\n",
      "Running episode 153\n",
      "Running episode 154\n",
      "Running episode 155\n",
      "Running episode 156\n",
      "Running episode 157\n",
      "Running episode 158\n",
      "Running episode 159\n",
      "Running episode 160\n",
      "Running episode 161\n",
      "Running episode 162\n",
      "Running episode 163\n",
      "Running episode 164\n",
      "Running episode 165\n",
      "Running episode 166\n",
      "Running episode 167\n",
      "Running episode 168\n",
      "Running episode 169\n",
      "Running episode 170\n",
      "Running episode 171\n",
      "Running episode 172\n",
      "Running episode 173\n",
      "Running episode 174\n",
      "Running episode 175\n",
      "Running episode 176\n",
      "Running episode 177\n",
      "Running episode 178\n",
      "Running episode 179\n",
      "Running episode 180\n",
      "Running episode 181\n",
      "Running episode 182\n",
      "Running episode 183\n",
      "Running episode 184\n",
      "Running episode 185\n",
      "Running episode 186\n",
      "Running episode 187\n",
      "Running episode 188\n",
      "Running episode 189\n",
      "Running episode 190\n",
      "Running episode 191\n",
      "Running episode 192\n",
      "Running episode 193\n",
      "Running episode 194\n",
      "Running episode 195\n",
      "Running episode 196\n",
      "Running episode 197\n",
      "Running episode 198\n",
      "Running episode 199\n"
     ]
    }
   ],
   "source": [
    "# TODO: число эпизодов подобрать\n",
    "episodes_count = 200\n",
    "\n",
    "\n",
    "for episode_num in range(episodes_count):\n",
    "    print(f\"Running episode {episode_num}\")\n",
    "    environment.restart()\n",
    "    environment.start_game()\n",
    "    \n",
    "    while not environment.has_crashed():\n",
    "        state = environment.get_screen()\n",
    "        if not environment.has_crashed(): \n",
    "            action = agent.select_action(state)\n",
    "            next_state, reward = environment.perform_action(action)\n",
    "            # Не сломались пока выполняли действие\n",
    "            agent.memory.push(state, action, next_state, reward)\n",
    "            if next_state is not None:\n",
    "                agent.update_reward(state, action, next_state, reward)\n",
    "                \n",
    "            \n",
    "# TODO: Если так ничего хорошего не выйдет, то делать Replay Memory\n",
    "#https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103c752d",
   "metadata": {},
   "source": [
    "###### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144eddd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
